\documentclass[]{article}
\voffset=-1.5cm
\oddsidemargin=0.0cm
\textwidth = 470pt

\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{framed}


% http://rstudio-pubs-static.s3.amazonaws.com/1940_f7997f0ead914ae897a445f5c94bc96f.html

%https://github.com/pcward/coursera_programming-r/blob/master/rankhospital.r

\begin{document}

\tableofcontents
\newpage

\section{Programming Exercise}

\subsection{Exercise: Dataset reporting function}
For an in-built data set (e.g. iris, mtcars etc), construct a function called \texttt{Report} that returns some or all of following outputs:

\begin{itemize}
\item dimensions of the data set (\texttt{dims})
\item names of components of the data set (\texttt{names})
\item summary statistics (\texttt{summary})
\end{itemize}
\noindent Use iris as the default data set.
\begin{framed}
\begin{verbatim}
Report <- function(dataset=iris,dims=FALSE,
     cnames=FALSE,smry=TRUE)
 {
 if(dims==TRUE)
  {
   print(dim(dataset))
  }
  if(cnames==TRUE)
  {
   print(names(dataset))
  }
   if(smry==TRUE)
  {
   print(summary(dataset))
  }
 }
Report()
\end{verbatim}
\end{framed}
\newpage
\noindent Constructing the output for this as a list. (Some lines of code to be added)

\begin{framed}
\begin{verbatim}
ReportList <- function(dataset=iris,dims=FALSE,
   cnames=FALSE,smry=TRUE)

 {

 output=list(dims=numeric(),cnames=character(),smry=list())

 if(dims==TRUE)
  {
   output$dims=dim(dataset)
  }

  if(cnames==TRUE)
  {
   output$cnames=names(dataset)
  }


  if(smry==TRUE)
  {
   output$smry=summary(dataset)
  }
  return(output)
 }



\end{verbatim}
\end{framed}

\begin{verbatim}
ReportList(iris)
ReportList(mtcars,T,T,F)
ReportList(mtcars,F,T,F)
\end{verbatim}
\newpage
\subsection{Data Set for this exercise}
The zip file contains 332 comma-separated-value (CSV) files containing pollution monitoring data for fine particulate matter (PM) air pollution at 332 locations in the United States. 

\bigskip
\noindent Each file contains data from a single monitor and the ID number for each monitor is contained in the file name. For example, data for monitor 200 is contained in the file ``200.csv". 

\bigskip
\noindent Each file contains three variables:
\begin{itemize}
\item \textbf{Date}: the date of the observation in YYYY-MM-DD format (year-month-day)
\item \textbf{sulfate}: the level of sulfate PM in the air on that date (measured in micrograms per cubic meter)
\item \textbf{nitrate}: the level of nitrate PM in the air on that date (measured in micrograms per cubic meter)
\end{itemize}
%-----------------------------------------------------%
\newpage
\subsection{Some Useful Functions}
\subsubsection{The \texttt{nchar()} function}
This command returns the number of characters in the argument.
\begin{verbatim}
> string=c("kevin")
> nchar(string)
[1] 5
> nchar(1001)
[1] 4
\end{verbatim}
\subsubsection{The \texttt{paste()} function}
This command creates a string of specified components. The default is to have whitespace between each component. This can be removed with the additional argument \texttt{sep=""}.
\begin{framed}
\begin{verbatim}
> x=5
> paste("file",x,".csv")
[1] "file 5 .csv"
>
> paste("file",x,".csv",sep="")
[1] "file5.csv"
\end{verbatim}
\end{framed}
\begin{verbatim}
> filenm(2)
[1] "file 2 .csv"
\end{verbatim}
\subsubsection{The \texttt{gsub()} function}
The \texttt{R} command \texttt{gsub()} is used to replace a character or piece of text with another in a specified string
\begin{verbatim}
> string=c("kevin")
> gsub("k","s",string)
[1] "sevin"
\end{verbatim}
\newpage
\subsubsection{The \texttt{list.files()} function}
This command is used to produce a list of files in a specified directory.
\begin{framed}
\begin{verbatim}
getwd() # working directory
list.files(getwd()) # List all files in working directory
\end{verbatim}
\end{framed}
\subsubsection{The \texttt{sprintf()} function}
This command returns a character vector containing a formatted combination of text and variable values. The structure of the command is \texttt{sprintf(format, input)}.
\begin{verbatim}
> sprintf("%f", pi)     
[1] "3.141593"
> sprintf("%.3f", pi)   # 3decimal places
[1] "3.142"
> sprintf("%1.0f", pi)   # no decimal places
[1] "3"
> sprintf("%5.1f", pi)  # 5 characters with whitespace
[1] "  3.1"  
> sprintf("%05.1f", pi)  #5 characters no whitespace
[1] "003.1"
> sprintf("%+f", pi)
[1] "+3.141593"
\end{verbatim}

To express asingle or double digit character integer as three character number
\begin{verbatim}
> x = 4
> sprintf("%03d", x)
[1] "004"
> 
> x=40
> sprintf("%03d", x)
[1] "040"
\end{verbatim}

For character data (i.e. strings) 
\begin{verbatim}
> sprintf("%s %d", "test", 1:3)
[1] "test 1" "test 2" "test 3"
\end{verbatim}
N.B $s$ for string and $d$ for integers.
\newpage
%---------------------------------------------------------------------- %
\subsection{Programming Assignment Part 1  - \texttt{pollutantmean.r}}
\begin{itemize}
\item Write a function named '\texttt{pollutantmean}' that calculates the mean of a pollutant (sulfate or nitrate) across a specified list of monitors. 
\item The function '\texttt{pollutantmean}' takes three arguments: '\texttt{directory}', '\texttt{pollutant}', and '\texttt{id}'. 
\item Given a vector monitor ID numbers, '\texttt{pollutantmean}' reads that monitors' particulate matter data from the directory specified in the 'directory' argument and returns the mean of the pollutant across all of the monitors, ignoring any missing values coded as NA. 
\item A prototype of the function is as follows
\end{itemize}


\begin{framed}
\begin{verbatim}
pollutantmean <- function(directory, pollutant, id = 1:332) {
## 'directory' is a character vector of length 1 indicating
## the location of the CSV files

## 'pollutant' is a character vector of length 1 indicating
## the name of the pollutant for which we will calculate the
## mean; either "sulfate" or "nitrate".

## 'id' is an integer vector indicating the monitor ID numbers
## to be used

## Return the mean of the pollutant across all monitors list
## in the 'id' vector (ignoring NA values)
}
\end{verbatim}
\end{framed}
You can see some example output from this function. The function that you write should be able to match this output. Please save your code to a file named \texttt{pollutantmean.R}.

\newpage


\subsection{Set Theory Commands}
Set theory commands are very useful in simplifying code. The \texttt{is.element()} command asks if a specified value is an element in a specified set. If so, the function returns "TRUE", otherwise "FALSE".

\begin{framed}
	\begin{verbatim}
	x <- c(2,4,8)
	y <- 1:6
	is.element(x,y)
	!is.element(x,y)
	x %in % y
	\end{verbatim}
\end{framed}

\begin{verbatim}
> x <- c(2,4,8)
> y <- 1:6
> is.element(x,y)
[1]  TRUE  TRUE FALSE
> !is.element(x,y)
[1] FALSE FALSE  TRUE
> 
> x %in% y
[1]  TRUE  TRUE FALSE
\end{verbatim}

\subsection*{Example: List of States Abbreviations}
\textit{(Extract relating to an exercise on a similar R Course)\\\\}
\noindent Let us look at the states (includes some US territories such as Guam, Puerto Rico and the US Virgin Islands). Using the \texttt{str()} command, we can see this variable is structured as a \textbf{factor}.
\begin{verbatim}
> summary(Hosp[,7])
AK  AL  AR  AZ  CA  CO  CT  DC  DE  FL  GA  GU  HI  IA  ID  IL  IN  KS 
17  98  77  77 341  72  32   8   6 180 132   1  19 109  30 179 124 118 
KY  LA  MA  MD  ME  MI  MN  MO  MS  MT  NC  ND  NE  NH  NJ  NM  NV  NY 
96 114  68  45  37 134 133 108  83  54 112  36  90  26  65  40  28 185 
OH  OK  OR  PA  PR  RI  SC  SD  TN  TX  UT  VA  VI  VT  WA  WI  WV  WY 
170 126  59 175  51  12  63  48 116 370  42  87   2  15  88 125  54  29
>
> str(Hosp[,7])
Factor w/ 54 levels "AK","AL","AR",..: 2 2 2 2 2 2 2 2 2 2 ..
\end{verbatim}

To generate a list of state names (as in abbreviations) can be generated by using the \texttt{unique()} and \texttt{as.character()} functions.
\begin{verbatim}
> as.character(unique(Hosp[,2]))
[1] "AL" "AK" "AZ" "AR" "CA" "CO" "CT" "DE" "DC" "FL" "GA"
[12] "HI" "ID" "IL" "IN" "IA" "KS" "KY" "LA" "ME" "MD" "MA"
[23] "MI" "MN" "MS" "MO" "MT" "NE" "NV" "NH" "NJ" "NM" "NY"
[34] "NC" "ND" "OH" "OK" "OR" "PA" "PR" "RI" "SC" "SD" "TN"
[45] "TX" "UT" "VT" "VI" "VA" "WA" "WV" "WI" "WY" "GU"

\end{verbatim}

We can then sort them using the \texttt{sort()} command.

\begin{framed}
	\begin{verbatim}
	StateList <- sort(as.character(unique(Hosp[,7])))
	\end{verbatim}
\end{framed}

\newpage

\begin{verbatim}
> StateList <- sort(as.character(unique(Hosp[,7])))
> is.element("XX",StateList)
[1] FALSE
> !is.element("XX",StateList)
[1] TRUE
>
\end{verbatim}
\newpage

\subsection{\texttt{R} code to check that inputs are valid}

\begin{framed}
	\begin{verbatim}
	# Generate a list of valid state abbreviations from data.
	
	ValidStates <- as.character(unique(Hosp[,2]))
	
	# construct a set of valid outcome names
	
	ValidOutcomes <- c("heart attack","heart failure","pneumonia")
	
	
	## Check that state is valid
	if(!is.element(state,ValidStates)){
	stop("invalid state")
	}
	## Check that outcome is valid
	if(!is.element(outcome,ValidOutcomes)){
	stop("invalid outcome")
	}
	
	\end{verbatim}
\end{framed}

%----------------------------------------------%
\subsection{Old Part 1 - \texttt{getmonitor.r}}
 \begin{itemize}
\item Write a function named '\texttt{getmonitor}' that takes three arguments: 'id', 'directory', and 'summarize'. \item Given a monitor ID number, 'getmonitor' reads that monitor's particulate matter data from the directory specified in the 'directory' argument and returns a data frame containing that monitor's data. 
 \item If 'summarize = TRUE', then 'getmonitor' produces a summary of the data frame with the 'summary' function and prints it to the console. \item A prototype of the function is as follows
 \end{itemize}
 \begin{framed}
 \begin{verbatim}
 getmonitor <- function(id, directory, summarize = FALSE) {
 
 ## 'id' is a vector of length 1 indicating the monitor ID
 ## number. The user can specify 'id' as either an integer, a
 ## character, or a numeric.
         
 ## 'directory' is a character vector of length 1 indicating
 ## the location of the CSV files
 
 ## 'summarize' is a logical indicating whether a summary of
 ## the data should be printed to the console; the default is
 ## FALSE
      
 ## Your code here
 }
 \end{verbatim}
 \end{framed}
 \newpage
 \subsection{Creating the file name}
 \begin{itemize}
  \item \texttt{directory} is going to get passed as a string. The correct program will obviously use "specdata".
  \item Using the \texttt{paste()} command, we can come up with a filename based on the directory and id.
 \begin{verbatim}
 > directory="specdata"
 > id = 3
 > 
 > paste(directory, "/", id, ".csv")
 [1] "specdata / 3 .csv"
 > 
 \end{verbatim}
  \item We must rectify the problem of the id number. As a string it is written with three characters. The first two characters would be zeros for the first 99 cases.
 We should have "\texttt{specdata / 003 .csv}".
 \item \textbf{using \texttt{nchar()}} : Before we implement the previous code, we need to replace all values with equivalent three character strings.
 \begin{verbatim}
 if (nchar(id) == 1) {
    	id <- paste("00", id)
    } else if (nchar(id) == 2) {
    	id <- paste("0", id)
    }
 \end{verbatim}

 \item Clearly there is whitespace where there shouldn't be. We will use the \texttt{gsub()} command to remove it. 
 \begin{verbatim}
 > dir <- gsub(" ", "", paste(directory, "/", id, ".csv"))
 > dir
 [1] "specdata/003.csv"
  \end{verbatim}
\newpage
   \item An alternative approach is to use the \texttt{sprintf()} command. (The command \texttt{as.numeric()} is to account for irregular inputs)
   \begin{verbatim}
   > id=2
   > sprintf("%03d", as.numeric(id))
   [1] "002"
   \end{verbatim}
   
 \item 
 \begin{framed}
 \begin{verbatim}
 paste(directory, "/", sprintf("%03d", as.numeric(id)),
   ".csv",sep = "")
 \end{verbatim}
 \end{framed}
 \end{itemize}
 \newpage
%--------------------------------------------------%
\subsection{Workable Programs}
\begin{framed}
\begin{verbatim}
 getmonitor <- function(id, directory, summarize = FALSE) {
 
   if (nchar(id) == 1) {
   	id <- paste("00", id)
   } else if (nchar(id) == 2) {
   	id <- paste("0", id)
   }
 
   filename <- gsub(" ", "", 
     paste(directory, "/", id, ".csv"))
   
   Data <- read.csv(filename, header=TRUE, sep="," )
 
   if (summarize == TRUE) {
   	print(summary(Data))
   }
 
   return(Data)
 }
  \end{verbatim}
 \end{framed}
 \newpage
%--------------------------------------------------%
\subsection{Another workable program}
 \begin{framed}
 \begin{verbatim}
 getmonitor <- function(id, directory, summarize = FALSE) {
 
     filename <- paste(directory, "/", sprintf("%03d", 
        as.numeric(id)), ".csv", sep = "")
 
     Data <- read.csv(filename, header=TRUE, sep="," )
 
     if (summarize==TRUE) {
         print(summary(Data))
     }
 
     return(Data)
 }
 
 \end{verbatim}
  \end{framed}
\newpage


\subsection{Programming Assignment Part 2 - \texttt{complete.r}}
\begin{itemize}
\item Write a function that reads a directory full of files and reports the number of completely observed cases in each data file. \item The function should return a data frame where the first column is the name of the file and the second column is the number of complete cases.
\end{itemize}

\bigskip
\noindent \textbf{Prototype:}
\begin{framed}
\begin{verbatim}
complete <- function(directory, id = 1:332) {
        ## 'directory' is a character vector of length 1 
        ## indicating the location of the CSV files

        ## 'id' is an integer vector indicating the monitor 
        ## ID numbers to be used
        
        ## Return a data frame of the form:
        ## id nobs
        ## 1  117
        ## 2  1041
        ## ...
        ## where 'id' is the monitor ID number and 
        ## 'nobs' is the number of complete cases
}
\end{verbatim} 
\end{framed}
\begin{itemize}
\item input : directory
\end{itemize}
\newpage
\subsection{The \texttt{complete.cases()} command}
Consider the \textit{\textbf{airquality}} data set (first seven rows for sake of brevity).
\begin{verbatim}
> airquality[1:7,]
  Ozone Solar.R Wind Temp Month Day
1    41     190  7.4   67     5   1
2    36     118  8.0   72     5   2
3    12     149 12.6   74     5   3
4    18     313 11.5   62     5   4
5    NA      NA 14.3   56     5   5
6    28      NA 14.9   66     5   6
7    23     299  8.6   65     5   7
>
> complete.cases(airquality[1:7,])
[1]  TRUE  TRUE  TRUE  TRUE FALSE FALSE  TRUE
\end{verbatim}
How many complete cases are there in the \textit{\textbf{airquality}} data set? LEt set up a subset of this data set that comprises only complete cases (lets call it \texttt{aq.comp} ), and then find the dimensions.
\begin{verbatim}
> dim(airquality)
[1] 153   6
>
> aq.comp <- airquality[complete.cases(airquality),] 
>
> dim(aq.comp)
[1] 111   6
\end{verbatim}

\newpage
\subsection{Number of logical-compliant elements}
How many elements in a vector fulfil a logical condition? Consider the output of the \texttt{complete.cases()} command in the last section. The output tells us which rows are complete cases. Suppose we simply want to find out how many complete cases there are, without resorting to creating new dataframes.
\begin{verbatim}
> complete.cases(airquality)
  [1]  TRUE  TRUE  TRUE  TRUE FALSE FALSE  TRUE  TRUE  TRUE FALSE
 [11] FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
.............

\end{verbatim}
We can use the \texttt{as.numeric()} function to turn the logical states into numbers (i.e. 0 and 1). We can then simply sum up the values.

\begin{framed}
\begin{verbatim}
as.numeric(complete.cases(airquality))
sum(as.numeric(complete.cases(airquality)))
\end{verbatim}
\end{framed}
\begin{verbatim}

> as.numeric(complete.cases(airquality))
  [1] 1 1 1 1 0 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1
 [32] 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1
..............

> sum(as.numeric(complete.cases(airquality)))
[1] 111
\end{verbatim}

\noindent This accords with our conclusion from the previous section, that there is 111 complete cases in the \textit{\textbf{airquality}} data set.
%---------------------------------------------------- %
\newpage
\subsection{Empty Data Frames}
We can create an ``empty" data frame that can be dynamically populated. Simply specify the name of the data frame, using the \texttt{data.frame()} command with no supplied arguments.
\begin{verbatim}
> mydata = data.frame()
> mydata
data frame with 0 columns and 0 rows
> 
> mydata=rbind(mydata,1:6)
> mydata
  X1L X2L X3L X4L X5L X6L
1   1   2   3   4   5   6
>
> mydata=rbind(mydata,7:12)
> mydata
  X1L X2L X3L X4L X5L X6L
1   1   2   3   4   5   6
2   7   8   9  10  11  12
\end{verbatim}

We can rename the column names of the dataframe using the \texttt{names()} function. The folllowing piece of code demonstrates the two functionalities of this command.

\begin{verbatim}
> names(mydata)
[1] "X1L" "X2L" "X3L" "X4L" "X5L" "X6L"
> names(mydata) <- c("A","B","C","D","E","F")
> names(mydata)
[1] "A" "B" "C" "D" "E" "F"
\end{verbatim}
\newpage
\subsection{Workable Solution}
\begin{framed}
\begin{verbatim}
complete <- function(directory, id = 1:332) {
    mydata = data.frame()
    for(item in id) {
        file <- sprintf("%s/%03d.csv", directory, item)
        data <- read.csv(file)
        
        rows <- sum(as.numeric(complete.cases(data)))
        mydata <- rbind(mydata, c(item, rows))
    }
    names(mydata) <- c("id", "nobs")
    return(mydata)
}
\end{verbatim}
\end{framed} 
\newpage

 
\subsection{Programming Assignment Part 2 : \texttt{corr.r} }
\begin{itemize}

\item Write a function that takes a directory of data files and a threshold for complete cases and calculates the correlation between sulfate and nitrate for monitor locations where the number of completely observed cases (on all variables) is greater than the threshold. \item The reference to completed cases implies that \texttt{complete.R} should be called by the function we are going to write. \item The function should return a vector of correlations for the monitors that meet the threshold requirement. \item If no monitors meet the threshold requirement, then the function should return a numeric vector of length 0.
\end{itemize}

%\textbf{Output} :
%\begin{verbatim}
%> directory
%[1] "specdata"
%> 
%> corr(directory)
%     id nobs
%1     1  117
%2     2 1041
%3     3  243
%4     4  474
%5     5  402
%6     6  228
%.......
%\end{verbatim}
\textbf{Prototype}: 
\begin{framed}
\begin{verbatim}
corr <- function(directory, threshold = 0) {
    ## 'directory' is a character vector of length 1 
    ## indicating the location of the CSV files

    ## 'threshold' is a numeric vector of length 1 indicating
    ## the number of completely observed observations (on 
    ## all variables) required to compute the correlation 
    ## between nitrate and sulfate; the default is 0

    ## Return a numeric vector of correlations
}
\end{verbatim}
\end{framed}
\newpage

\subsection{Part 3 Exercise}

\begin{itemize}
\item[Input] \textit{\textbf{directory}} is a character vector of length 1 indicating the
    location of the CSV files. 
\item[Input] \textit{\textbf{threshold}} is a numeric vector of length 1
   indicating the number of completely observed observations (on all variables) required to compute the correlation between nitrate and sulfate; \\ The default for \textit{\textbf{threshold}} is 0. 
\item[Output] The function return a numeric vector of correlations.
\end{itemize}    
\begin{framed}    
\begin{verbatim}
corr <- function(directory, threshold = 0) {

    corrsNum <- numeric(0)

    # Get a data frame as ID = 1:332
    CompObs <- complete("specdata")

    # Apply the threshold condition
    # Reduce CompObs to those with enough
    
    CompObs <- CompObs[CompObs$nobs > threshold, ]

    for (cid in CompObs$id) {
        # Get a data frame as ID in $id
        monDfr <- getmonitor(cid, directory)

        # Calculate correlation between variables
        corrsNum <- c(corrsNum, 
          cor(monDfr$sulfate,monDfr$nitrate, 
          use = "pairwise.complete.obs"))
        }

    return(corrsNum)
    }
\end{verbatim}
\end{framed}
\newpage
Another workable solution
\begin{verbatim}
corr <- function(directory, threshold = 0) {
  
    cordata <- c()

    files <- list.files(directory)
    for(file in files){
        # get the file and its data
        file <- sprintf("%s/%s", directory, file)
        data <- read.csv(file)

        # get the complete data (and count) for that file
        good <- data[complete.cases(data),]
        rows <- nrow(good)

        # only calc correlation on files with more than
        # 'threshold' complete rows
        if(rows > threshold){
            correlation <- cor(good$sulfate, good$nitrate)
            cordata <- append(cordata, correlation)
        }
    }

    # if no data (no files with number of rows > threshold
    
    if(length(cordata) < 1){
        cordata <- vector(mode="numeric", length=0)
    }

    
    return(cordata)
}
\end{verbatim}	


\end{document}

% - https://github.com/Xiaodan/Coursera-R-Programming/blob/master/week2/complete.R
%---------------------------------------------------------------- %

setwd("~/Desktop/Online Coursera/Coursera-R-Programming/week2/")
#getwd()
#list.files()

pollutantmean <- function(directory, pollutant = "sulfate", id = 1:332) {
	## 'directory' is a character vector of length 1 indicating
	## the location of the CSV files
	
	## 'pollutant' is a character vector of length 1 indicating
	## the name of the pollutant for which we will calculate the
	## mean; either "sulfate" or "nitrate".
	
	## 'id' is an integer vector indicating the monitor ID numbers
	## to be used
	
	## Return the mean of the pollutant across all monitors list
	## in the 'id' vector (ignoring NA values)
	
	# set working directory
	if(grep("specdata", directory) == 1) {
		directory <- ("./specdata/")
	}
	# initialize a vector to hold the pollutant data
	mean_vector <- c()
	# find all files in the specdata folder
	all_files <- as.character( list.files(directory) )
	file_paths <- paste(directory, all_files, sep="")
	for(i in id) {
		current_file <- read.csv(file_paths[i], header=T, sep=",")
		head(current_file)
		pollutant
		na_removed <- current_file[!is.na(current_file[, pollutant]), pollutant]
		mean_vector <- c(mean_vector, na_removed)
	}
	result <- mean(mean_vector)
	return(round(result, 3)) 
}

# tests
pollutantmean("specdata", "sulfate", 1:10) == 4.064
pollutantmean("specdata", "nitrate", 70:72) == 1.706
pollutantmean("specdata", "nitrate", 23) == 1.281

$-------------------------------------------------------------------- %